{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy import stats\n",
    "from xgboost import XGBRegressor\n",
    "import joblib\n",
    "\n",
    "cols_name = np.load('D:\\dataset\\dataset\\cols_name.npy', allow_pickle=True)\n",
    "train_df = pd.read_parquet('D:\\\\dataset\\\\dataset\\\\train_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = train_df.loc[train_df['Moons']<225]\n",
    "val_split = train_df.loc[train_df['Moons']>=225]\n",
    "len(train_split), len(val_split)\n",
    "\n",
    "\n",
    "x_train = train_split.iloc[:, 2:-4].values  \n",
    "y_train = train_split['target_w'].values    \n",
    "\n",
    "x_val = val_split.iloc[:, 2:-4].values     \n",
    "y_val = val_split['target_w'].values         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = train_split['Moons'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape) \n",
    "print(y_train.shape)  \n",
    "\n",
    "print(x_val.shape)    \n",
    "print(y_val.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearman_scorer(y_true, y_pred):\n",
    "    return stats.spearmanr(y_true, y_pred).correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "train_df = pd.read_parquet('D:\\\\dataset\\\\dataset\\\\test_df.parquet')\n",
    "\n",
    "\n",
    "train_split = train_df.loc[train_df['Moons'] < 390]\n",
    "val_split = train_df.loc[(train_df['Moons'] >= 390) & (train_df['Moons'] <400 )]\n",
    "test_split = train_df.loc[train_df['Moons'] >= 400]\n",
    "print(train_split.shape)\n",
    "print(val_split.shape)\n",
    "test_split.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_features(train_split, target_names, n_features=20):\n",
    "    \"\"\"\n",
    "    Lấy các đặc trưng tốt nhất cho mỗi biến mục tiêu.\n",
    "    \"\"\"\n",
    "    top_features = {}\n",
    "    features_to_exclude = ['target_w', 'target_r', 'target_g', 'target_b']\n",
    "    \n",
    "    for target in target_names:\n",
    "        train_features_only = train_split.drop(columns=features_to_exclude)\n",
    "        target_corr = train_features_only.corrwith(train_split[target]).reset_index()\n",
    "        target_corr.columns = ['feature', 'correlation']\n",
    "        target_corr['correlation'] = abs(target_corr['correlation'])\n",
    "        top_features[target] = target_corr.sort_values(by='correlation', ascending=False)['feature'][:n_features].tolist()\n",
    "    \n",
    "    return top_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importances(model, feature_names):\n",
    "    \"\"\"\n",
    "    Lấy điểm quan trọng của các đặc trưng từ mô hình XGBoost.\n",
    "    \"\"\"\n",
    "    importances = model.feature_importances_\n",
    "    feature_importances = dict(zip(feature_names, importances))\n",
    "    return feature_importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "\n",
    "model_paths = {\n",
    "    'target_w': 'D:\\\\dataset\\\\model_target_w.joblib',\n",
    "    'target_r': 'D:\\\\dataset\\\\model_target_r.joblib',\n",
    "    'target_g': 'D:\\\\dataset\\\\model_target_g.joblib',\n",
    "    'target_b': 'D:\\\\dataset\\\\model_target_b.joblib'\n",
    "}\n",
    "\n",
    "\n",
    "target_names = ['target_w', 'target_r', 'target_g', 'target_b']\n",
    "\n",
    "results = {}\n",
    "\n",
    "\n",
    "for target in target_names:\n",
    "    model = load(model_paths[target])\n",
    "    feature_names = x_train.columns  \n",
    "\n",
    "  \n",
    "    feature_importances = get_feature_importances(model, feature_names)\n",
    "\n",
    " \n",
    "    results[target] = {\n",
    "        'model': model,\n",
    "        'feature_importances': feature_importances,\n",
    "        'top_features': get_top_features(train_split, [target])[target]\n",
    "    }\n",
    "\n",
    "\n",
    "for target, result in results.items():\n",
    "    print(f\"\\nModel saved to: {model_paths[target]}\")\n",
    "    print(\"\\nTop Features:\")\n",
    "    print(result['top_features'])  \n",
    "\n",
    "    print(\"\\nFeature Importances:\")\n",
    "    for feature, importance in result['feature_importances'].items():\n",
    "        print(f\"{feature}: {importance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "import joblib\n",
    "\n",
    "\n",
    "cols_name = np.load('D:\\\\dataset\\\\dataset\\\\cols_name.npy', allow_pickle=True)\n",
    "train_df = pd.read_parquet('D:\\\\dataset\\\\dataset\\\\train_data.parquet')\n",
    "\n",
    "\n",
    "train_split = train_df.loc[train_df['Moons'] < 200]\n",
    "val_split = train_df.loc[(train_df['Moons'] >= 200) & (train_df['Moons'] < 225)]\n",
    "test_split = train_df.loc[train_df['Moons'] >= 225]\n",
    "\n",
    "x_train = train_split.iloc[:, 2:-4]  \n",
    "y_train = train_split['target_w'].values  \n",
    "\n",
    "x_val = val_split.iloc[:, 2:-4] \n",
    "y_val = val_split['target_w'].values \n",
    "\n",
    "x_test = test_split.iloc[:, 2:-4] \n",
    "y_test = test_split['target_w'].values  \n",
    "\n",
    "groups = train_split['Moons'].values\n",
    "\n",
    "def get_top_features(train_split, target_names, n_features=30):\n",
    "    \"\"\"\n",
    "    Lấy các đặc trưng tốt nhất cho mỗi biến mục tiêu.\n",
    "    \"\"\"\n",
    "    top_features = {}\n",
    "    features_to_exclude = ['target_w', 'target_r', 'target_g', 'target_b']\n",
    "    \n",
    "    for target in target_names:\n",
    "        train_features_only = train_split.drop(columns=features_to_exclude)\n",
    "        target_corr = train_features_only.corrwith(train_split[target]).reset_index()\n",
    "        target_corr.columns = ['feature', 'correlation']\n",
    "        target_corr['correlation'] = abs(target_corr['correlation'])\n",
    "        top_features[target] = target_corr.sort_values(by='correlation', ascending=False)['feature'][:n_features].tolist()\n",
    "    \n",
    "    return top_features \n",
    "\n",
    "def get_feature_importances(model, feature_names):\n",
    "    \"\"\"\n",
    "    Lấy điểm quan trọng của các đặc trưng từ mô hình XGBoost.\n",
    "    \"\"\"\n",
    "    importances = model.feature_importances_\n",
    "    feature_importances = dict(zip(feature_names, importances))\n",
    "    sorted_features = sorted(feature_importances.items(), key=lambda item: item[1], ascending=False)\n",
    "    return sorted_features\n",
    "\n",
    "def train_and_evaluate(train_split, model_paths):\n",
    "    \n",
    "    \n",
    "    target_names = ['target_w', 'target_r', 'target_g', 'target_b']\n",
    "    \n",
    "    \n",
    "    top_features_dict = get_top_features(train_split, target_names, n_features=130)\n",
    "    \n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for target in target_names:\n",
    "        train_top_features = train_split[top_features_dict[target]]\n",
    "        X = train_top_features.values\n",
    "        y = train_split[target].values\n",
    "        \n",
    "        \n",
    "        best_params = {\n",
    "        'learning_rate': 0.006795227920929744,\n",
    "        'max_depth': 11, \n",
    "        'subsample': 0.9005341830239901, \n",
    "        'colsample_bytree': 0.39363685180823027, \n",
    "        'reg_lambda': 25.490987283296956, \n",
    "        'grow_policy': 'lossguide',\n",
    "        'max_cat_to_onehot': 46,\n",
    "        'n_estimators': 10000,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'tree_method': 'hist',\n",
    "        'random_state': 0,\n",
    "        'enable_categorical': True,\n",
    "    }\n",
    "        \n",
    "        \n",
    "        model = XGBRegressor(**best_params)\n",
    "        model.fit(X, y)\n",
    "        \n",
    "        \n",
    "        model_path = model_paths[target]\n",
    "        joblib.dump(model, model_path)\n",
    "        \n",
    "    \n",
    "        feature_importances = get_feature_importances(model, top_features_dict[target])\n",
    "        \n",
    "        results[target] = {\n",
    "            'model': model,\n",
    "            'params': best_params,\n",
    "            'top_features': top_features_dict[target],\n",
    "            'feature_importances': feature_importances\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "model_paths = {\n",
    "    'target_w': 'D:\\\\dataset\\\\dataset\\\\model_target_w.joblib',\n",
    "    'target_r': 'D:\\\\dataset\\\\dataset\\\\model_target_r.joblib',\n",
    "    'target_g': 'D:\\\\dataset\\\\dataset\\\\model_target_g.joblib',\n",
    "    'target_b': 'D:\\\\dataset\\\\dataset\\\\model_target_b.joblib'\n",
    "}\n",
    "\n",
    "\n",
    "results = train_and_evaluate(train_split, model_paths)\n",
    "\n",
    "\n",
    "for target, result in results.items():\n",
    "    print(f\"\\nModel saved to: {model_paths[target]}\")\n",
    "    print(\"\\nBest Parameters:\")\n",
    "    for key, value in result['params'].items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    print(\"\\nTop Features:\")\n",
    "    print(result['top_features'])  \n",
    "\n",
    "    print(\"\\nFeature Importances:\")\n",
    "    for feature, importance in result['feature_importances']:\n",
    "        print(f\"{feature}: {importance}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
